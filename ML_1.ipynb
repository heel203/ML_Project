{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3iWWLM4vOD/yVwB8P316y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heel203/ML_Project/blob/main/ML_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cynS1RBXcylC"
      },
      "source": [
        "> Code Illustration during `ml_project` 2.0 for perception training\n",
        "\n",
        "**Date created** :- May 29, 2021\n",
        "\n",
        "\n",
        "**Author** :- [Heel Patel](https://www.linkedin.com/in/heel-patel-95aa76174/)\n",
        "\n",
        "\n",
        "**Reach Out** :- [GitHub](https://github.com/heel203) | [LinkedIn](https://www.linkedin.com/in/heel-patel-95aa76174/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy7NZSSs7iJA"
      },
      "source": [
        "#Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kmXrpAn76Yq"
      },
      "source": [
        "Teach Model to predict on the following equation\n",
        "\n",
        "\n",
        "Equation :- `y = 10x`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4WJLZ_u8S8j"
      },
      "source": [
        "#Data Creation\n",
        "\n",
        "Since the equation we want to teach our model is `y = 10x`, we need the following dataset\n",
        "\n",
        "```\n",
        "x = [0, 1, 2, 3, 4, 5,..]\n",
        "\n",
        "y = [0, 10, 20, 30, 40, 50,..]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsi-gFGX8ke5",
        "outputId": "75bd895c-641b-4b2b-86ee-2c6f72b9b7bb"
      },
      "source": [
        "x = [i for i in range(20+1)]\n",
        "print (x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wdrS_kO8wVK",
        "outputId": "96340d74-e886-4132-d5e4-42f3121ded76"
      },
      "source": [
        "y = [i for i in range(10*20+1) if i%10==0]\n",
        "print (y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ougFoQf79Lfx"
      },
      "source": [
        "# Approach 1\n",
        "*Non ML approach*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_zqZD5J9W0z"
      },
      "source": [
        "Defining a function for the equation `y = 10x`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfd51S8-9aUk",
        "outputId": "938d0de3-8c06-44d7-f642-6d53e9c7054e"
      },
      "source": [
        "def tableofTen(x):\n",
        "  y = 10*x\n",
        "  return y\n",
        "\n",
        "\n",
        "for value in x:\n",
        "  print(tableofTen(value))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-uQl1Ur9qvA"
      },
      "source": [
        "# Approach 2\n",
        "*ML Approach*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58iAB6mX9zv0"
      },
      "source": [
        "We got really excited to try ML out during the course so we ended up training a neuron on the table of 10, probably something that no one would ever use again, lol\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxXPEh9N95h6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gZkB00x95kp"
      },
      "source": [
        "Spliting data unto training and testing-\n",
        "\n",
        "- `xTrain` for training data\n",
        "- `yTrain` for training labels\n",
        "- `xTest` for testing data\n",
        "- `yTest` for testing labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40vCTXmd-3jK",
        "outputId": "74a1c4eb-4f34-445a-be0d-65f711e38895"
      },
      "source": [
        "print(f'This is x:{x}')\n",
        "print(f'This is y:{y}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is x:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "This is y:[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdMr74z6_jRy",
        "outputId": "6e0da1d2-b55b-44eb-8b69-9b4dc5b7fd49"
      },
      "source": [
        "xTrain = x[:-5] #Training Data\n",
        "yTrain = y[:-5] #Training Labels\n",
        "\n",
        "xTest = x[-5:] #Testing Data\n",
        "yTest = y[-5:] #Testing Labels\n",
        "\n",
        "print(f'''\n",
        "Training Data:\n",
        "\n",
        "xTrain : {xTrain}\n",
        "yTrain : {yTrain}\n",
        "\n",
        "Testing Data:\n",
        "\n",
        "xTest : {xTest}\n",
        "yTest : {yTest}\n",
        "''')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Data:\n",
            "\n",
            "xTrain : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "yTrain : [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
            "\n",
            "Testing Data:\n",
            "\n",
            "xTest : [16, 17, 18, 19, 20]\n",
            "yTest : [160, 170, 180, 190, 200]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1xqcFDu_tmP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBmtBN9LABth"
      },
      "source": [
        "#perceptron model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(units=1, input_shape=[1]) \n",
        "])\n",
        "\n",
        "#unit here denotes the number of neurons and input_shape denotes the shape of the input data that you provide your neuron here"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrSB5AuHAN59"
      },
      "source": [
        "### Mean Absolute Error\n",
        "\n",
        "$${\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-x_{i}\\right|}{n}}}\n",
        "$$\n",
        "\n",
        "where,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frPPxk7FAWBs"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mae')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S9KLRbtAZ0s",
        "outputId": "1751c6d4-68ed-49b8-9bc7-6ca47b3e0e68"
      },
      "source": [
        "numEpoch = 500  \n",
        "model.fit(x=xTrain, y=yTrain, validation_data=(xTest, yTest), epochs=numEpoch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 77.0963 - val_loss: 185.0120\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 77.0879 - val_loss: 184.9930\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 77.0795 - val_loss: 184.9740\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 77.0711 - val_loss: 184.9550\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 77.0628 - val_loss: 184.9360\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 77.0544 - val_loss: 184.9170\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 77.0460 - val_loss: 184.8980\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 77.0376 - val_loss: 184.8790\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 77.0293 - val_loss: 184.8600\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 77.0209 - val_loss: 184.8410\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 77.0125 - val_loss: 184.8221\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 77.0042 - val_loss: 184.8031\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.9958 - val_loss: 184.7841\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 76.9874 - val_loss: 184.7650\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 76.9790 - val_loss: 184.7461\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.9707 - val_loss: 184.7271\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.9623 - val_loss: 184.7081\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.9539 - val_loss: 184.6891\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.9455 - val_loss: 184.6701\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.9372 - val_loss: 184.6511\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.9288 - val_loss: 184.6321\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.9204 - val_loss: 184.6131\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.9121 - val_loss: 184.5941\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 76.9037 - val_loss: 184.5751\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.8953 - val_loss: 184.5561\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 76.8869 - val_loss: 184.5371\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.8786 - val_loss: 184.5181\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.8702 - val_loss: 184.4991\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.8618 - val_loss: 184.4801\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 76.8535 - val_loss: 184.4611\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.8451 - val_loss: 184.4421\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.8367 - val_loss: 184.4231\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.8283 - val_loss: 184.4041\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.8200 - val_loss: 184.3851\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 76.8116 - val_loss: 184.3661\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.8032 - val_loss: 184.3471\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 76.7948 - val_loss: 184.3281\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.7865 - val_loss: 184.3091\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 76.7781 - val_loss: 184.2901\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.7697 - val_loss: 184.2711\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 76.7613 - val_loss: 184.2521\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.7530 - val_loss: 184.2331\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.7446 - val_loss: 184.2141\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.7362 - val_loss: 184.1951\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.7278 - val_loss: 184.1761\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.7195 - val_loss: 184.1571\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 76.7111 - val_loss: 184.1381\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.7027 - val_loss: 184.1191\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 76.6944 - val_loss: 184.1001\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.6860 - val_loss: 184.0811\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.6776 - val_loss: 184.0621\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 76.6692 - val_loss: 184.0431\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 76.6609 - val_loss: 184.0241\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 76.6525 - val_loss: 184.0051\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.6441 - val_loss: 183.9861\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.6357 - val_loss: 183.9671\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.6274 - val_loss: 183.9481\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.6190 - val_loss: 183.9291\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.6106 - val_loss: 183.9101\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 76.6022 - val_loss: 183.8911\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.5939 - val_loss: 183.8721\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 76.5855 - val_loss: 183.8531\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.5771 - val_loss: 183.8342\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.5687 - val_loss: 183.8151\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.5604 - val_loss: 183.7962\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.5520 - val_loss: 183.7771\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 76.5436 - val_loss: 183.7581\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.5352 - val_loss: 183.7392\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.5269 - val_loss: 183.7202\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.5185 - val_loss: 183.7011\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.5101 - val_loss: 183.6822\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.5018 - val_loss: 183.6632\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.4934 - val_loss: 183.6442\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.4850 - val_loss: 183.6252\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.4766 - val_loss: 183.6062\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.4682 - val_loss: 183.5872\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.4599 - val_loss: 183.5682\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.4515 - val_loss: 183.5492\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.4431 - val_loss: 183.5302\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.4348 - val_loss: 183.5112\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.4264 - val_loss: 183.4922\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.4180 - val_loss: 183.4732\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.4096 - val_loss: 183.4541\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.4013 - val_loss: 183.4352\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.3929 - val_loss: 183.4162\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.3845 - val_loss: 183.3972\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.3761 - val_loss: 183.3782\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.3678 - val_loss: 183.3592\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.3594 - val_loss: 183.3402\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 76.3510 - val_loss: 183.3212\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.3426 - val_loss: 183.3022\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.3343 - val_loss: 183.2832\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.3259 - val_loss: 183.2642\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.3175 - val_loss: 183.2452\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.3091 - val_loss: 183.2262\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 76.3008 - val_loss: 183.2072\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.2924 - val_loss: 183.1882\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.2840 - val_loss: 183.1692\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.2757 - val_loss: 183.1502\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.2673 - val_loss: 183.1312\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.2589 - val_loss: 183.1122\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.2505 - val_loss: 183.0932\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.2421 - val_loss: 183.0742\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.2338 - val_loss: 183.0552\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 76.2254 - val_loss: 183.0362\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.2170 - val_loss: 183.0172\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.2086 - val_loss: 182.9982\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.2003 - val_loss: 182.9792\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.1919 - val_loss: 182.9602\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.1835 - val_loss: 182.9412\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 76.1752 - val_loss: 182.9222\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 76.1668 - val_loss: 182.9032\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 76.1584 - val_loss: 182.8842\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 76.1500 - val_loss: 182.8652\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.1416 - val_loss: 182.8462\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.1333 - val_loss: 182.8272\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.1249 - val_loss: 182.8082\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.1165 - val_loss: 182.7892\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.1082 - val_loss: 182.7702\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.0998 - val_loss: 182.7512\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 76.0914 - val_loss: 182.7322\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 76.0830 - val_loss: 182.7132\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 76.0747 - val_loss: 182.6942\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.0663 - val_loss: 182.6752\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 76.0579 - val_loss: 182.6562\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 76.0495 - val_loss: 182.6372\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 76.0412 - val_loss: 182.6182\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.0328 - val_loss: 182.5992\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.0244 - val_loss: 182.5802\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.0160 - val_loss: 182.5612\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 76.0077 - val_loss: 182.5422\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.9993 - val_loss: 182.5232\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.9909 - val_loss: 182.5042\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.9825 - val_loss: 182.4852\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 75.9742 - val_loss: 182.4662\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.9658 - val_loss: 182.4472\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.9574 - val_loss: 182.4282\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.9490 - val_loss: 182.4092\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.9407 - val_loss: 182.3902\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.9323 - val_loss: 182.3712\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.9239 - val_loss: 182.3522\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 75.9155 - val_loss: 182.3332\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.9072 - val_loss: 182.3142\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.8988 - val_loss: 182.2952\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 75.8904 - val_loss: 182.2762\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.8820 - val_loss: 182.2572\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.8737 - val_loss: 182.2382\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.8653 - val_loss: 182.2192\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 75.8569 - val_loss: 182.2002\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.8485 - val_loss: 182.1812\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.8402 - val_loss: 182.1622\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.8318 - val_loss: 182.1432\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.8234 - val_loss: 182.1242\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.8150 - val_loss: 182.1052\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 75.8067 - val_loss: 182.0862\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.7983 - val_loss: 182.0672\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.7899 - val_loss: 182.0482\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.7816 - val_loss: 182.0292\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.7732 - val_loss: 182.0102\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 75.7648 - val_loss: 181.9912\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.7564 - val_loss: 181.9722\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 75.7480 - val_loss: 181.9532\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.7397 - val_loss: 181.9342\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 75.7313 - val_loss: 181.9152\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.7229 - val_loss: 181.8962\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.7146 - val_loss: 181.8772\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.7062 - val_loss: 181.8582\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.6978 - val_loss: 181.8392\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.6894 - val_loss: 181.8202\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.6811 - val_loss: 181.8012\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.6727 - val_loss: 181.7822\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.6643 - val_loss: 181.7632\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.6559 - val_loss: 181.7442\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.6476 - val_loss: 181.7252\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.6392 - val_loss: 181.7062\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.6308 - val_loss: 181.6872\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.6224 - val_loss: 181.6682\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 75.6141 - val_loss: 181.6492\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.6057 - val_loss: 181.6302\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 75.5973 - val_loss: 181.6112\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.5889 - val_loss: 181.5922\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.5806 - val_loss: 181.5732\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.5722 - val_loss: 181.5542\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.5638 - val_loss: 181.5352\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.5554 - val_loss: 181.5162\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.5471 - val_loss: 181.4972\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.5387 - val_loss: 181.4782\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.5303 - val_loss: 181.4592\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 75.5219 - val_loss: 181.4402\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 75.5136 - val_loss: 181.4212\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.5052 - val_loss: 181.4022\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 75.4968 - val_loss: 181.3832\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.4884 - val_loss: 181.3642\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.4801 - val_loss: 181.3452\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.4717 - val_loss: 181.3262\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.4633 - val_loss: 181.3072\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 75.4549 - val_loss: 181.2882\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.4466 - val_loss: 181.2692\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 75.4382 - val_loss: 181.2502\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 75.4298 - val_loss: 181.2312\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.4214 - val_loss: 181.2122\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.4131 - val_loss: 181.1932\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 75.4047 - val_loss: 181.1742\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.3963 - val_loss: 181.1552\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.3879 - val_loss: 181.1362\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 75.3796 - val_loss: 181.1172\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.3712 - val_loss: 181.0982\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.3628 - val_loss: 181.0792\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.3544 - val_loss: 181.0602\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.3461 - val_loss: 181.0412\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 75.3377 - val_loss: 181.0222\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.3293 - val_loss: 181.0032\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 75.3209 - val_loss: 180.9842\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.3126 - val_loss: 180.9652\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 75.3042 - val_loss: 180.9462\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.2958 - val_loss: 180.9272\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.2874 - val_loss: 180.9082\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.2791 - val_loss: 180.8892\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.2707 - val_loss: 180.8702\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.2623 - val_loss: 180.8512\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.2539 - val_loss: 180.8322\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.2456 - val_loss: 180.8132\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.2372 - val_loss: 180.7942\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.2288 - val_loss: 180.7752\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.2204 - val_loss: 180.7562\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.2121 - val_loss: 180.7372\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.2037 - val_loss: 180.7182\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.1953 - val_loss: 180.6992\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.1869 - val_loss: 180.6802\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 75.1786 - val_loss: 180.6612\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 75.1702 - val_loss: 180.6422\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 75.1618 - val_loss: 180.6232\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.1534 - val_loss: 180.6042\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.1451 - val_loss: 180.5852\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.1367 - val_loss: 180.5662\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.1283 - val_loss: 180.5472\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 75.1199 - val_loss: 180.5282\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.1116 - val_loss: 180.5092\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.1032 - val_loss: 180.4902\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.0948 - val_loss: 180.4712\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 75.0864 - val_loss: 180.4522\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.0781 - val_loss: 180.4332\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75.0697 - val_loss: 180.4142\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.0613 - val_loss: 180.3952\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 75.0529 - val_loss: 180.3762\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 75.0446 - val_loss: 180.3572\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 75.0362 - val_loss: 180.3382\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.0278 - val_loss: 180.3192\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.0195 - val_loss: 180.3002\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 75.0111 - val_loss: 180.2812\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 75.0027 - val_loss: 180.2622\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 74.9943 - val_loss: 180.2432\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.9859 - val_loss: 180.2242\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.9776 - val_loss: 180.2052\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.9692 - val_loss: 180.1862\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.9608 - val_loss: 180.1672\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.9525 - val_loss: 180.1482\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.9441 - val_loss: 180.1292\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.9357 - val_loss: 180.1102\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.9273 - val_loss: 180.0912\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.9189 - val_loss: 180.0722\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 74.9106 - val_loss: 180.0532\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.9022 - val_loss: 180.0342\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.8938 - val_loss: 180.0152\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.8855 - val_loss: 179.9962\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.8771 - val_loss: 179.9772\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.8687 - val_loss: 179.9583\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.8603 - val_loss: 179.9392\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.8520 - val_loss: 179.9202\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.8436 - val_loss: 179.9012\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.8352 - val_loss: 179.8822\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.8268 - val_loss: 179.8632\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.8185 - val_loss: 179.8442\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 74.8101 - val_loss: 179.8252\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.8017 - val_loss: 179.8062\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.7933 - val_loss: 179.7872\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.7850 - val_loss: 179.7682\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.7766 - val_loss: 179.7492\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.7682 - val_loss: 179.7302\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 74.7598 - val_loss: 179.7112\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.7514 - val_loss: 179.6922\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.7431 - val_loss: 179.6732\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.7347 - val_loss: 179.6543\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.7263 - val_loss: 179.6353\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.7180 - val_loss: 179.6162\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.7096 - val_loss: 179.5972\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.7012 - val_loss: 179.5782\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.6928 - val_loss: 179.5592\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.6845 - val_loss: 179.5403\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 74.6761 - val_loss: 179.5212\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.6677 - val_loss: 179.5022\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.6593 - val_loss: 179.4832\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.6510 - val_loss: 179.4642\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.6426 - val_loss: 179.4453\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 74.6342 - val_loss: 179.4263\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.6258 - val_loss: 179.4073\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.6175 - val_loss: 179.3882\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.6091 - val_loss: 179.3693\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.6007 - val_loss: 179.3503\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.5923 - val_loss: 179.3313\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.5840 - val_loss: 179.3123\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.5756 - val_loss: 179.2932\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 74.5672 - val_loss: 179.2742\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.5588 - val_loss: 179.2552\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.5505 - val_loss: 179.2363\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.5421 - val_loss: 179.2173\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.5337 - val_loss: 179.1983\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.5253 - val_loss: 179.1792\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.5170 - val_loss: 179.1602\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 74.5086 - val_loss: 179.1413\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.5002 - val_loss: 179.1223\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.4918 - val_loss: 179.1032\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.4835 - val_loss: 179.0842\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.4751 - val_loss: 179.0653\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.4667 - val_loss: 179.0462\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.4583 - val_loss: 179.0273\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.4500 - val_loss: 179.0083\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.4416 - val_loss: 178.9892\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 74.4332 - val_loss: 178.9702\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.4248 - val_loss: 178.9512\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.4165 - val_loss: 178.9323\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.4081 - val_loss: 178.9133\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.3997 - val_loss: 178.8943\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.3913 - val_loss: 178.8753\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 74.3830 - val_loss: 178.8562\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.3746 - val_loss: 178.8372\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.3662 - val_loss: 178.8183\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.3578 - val_loss: 178.7993\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.3495 - val_loss: 178.7803\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.3411 - val_loss: 178.7613\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.3327 - val_loss: 178.7422\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.3243 - val_loss: 178.7233\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.3160 - val_loss: 178.7043\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.3076 - val_loss: 178.6853\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.2992 - val_loss: 178.6663\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.2908 - val_loss: 178.6472\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.2825 - val_loss: 178.6283\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.2741 - val_loss: 178.6093\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.2657 - val_loss: 178.5903\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.2573 - val_loss: 178.5713\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 74.2490 - val_loss: 178.5523\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 74.2406 - val_loss: 178.5333\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.2322 - val_loss: 178.5143\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.2238 - val_loss: 178.4953\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.2155 - val_loss: 178.4763\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.2071 - val_loss: 178.4573\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.1987 - val_loss: 178.4383\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 74.1903 - val_loss: 178.4193\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.1820 - val_loss: 178.4003\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.1736 - val_loss: 178.3813\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 74.1652 - val_loss: 178.3623\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.1568 - val_loss: 178.3432\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.1485 - val_loss: 178.3243\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.1401 - val_loss: 178.3053\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.1317 - val_loss: 178.2863\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.1234 - val_loss: 178.2673\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.1150 - val_loss: 178.2483\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.1066 - val_loss: 178.2293\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.0982 - val_loss: 178.2103\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.0898 - val_loss: 178.1913\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 74.0815 - val_loss: 178.1723\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 74.0731 - val_loss: 178.1533\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 74.0647 - val_loss: 178.1342\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.0564 - val_loss: 178.1153\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.0480 - val_loss: 178.0963\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74.0396 - val_loss: 178.0773\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 74.0312 - val_loss: 178.0583\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 74.0228 - val_loss: 178.0393\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.0145 - val_loss: 178.0202\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 74.0061 - val_loss: 178.0013\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.9977 - val_loss: 177.9823\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.9893 - val_loss: 177.9633\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.9810 - val_loss: 177.9443\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.9726 - val_loss: 177.9253\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.9642 - val_loss: 177.9063\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.9558 - val_loss: 177.8873\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.9475 - val_loss: 177.8683\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.9391 - val_loss: 177.8493\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.9307 - val_loss: 177.8303\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.9223 - val_loss: 177.8112\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 73.9140 - val_loss: 177.7923\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.9056 - val_loss: 177.7733\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 73.8972 - val_loss: 177.7543\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.8889 - val_loss: 177.7353\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.8805 - val_loss: 177.7163\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 73.8721 - val_loss: 177.6973\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 73.8637 - val_loss: 177.6783\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.8553 - val_loss: 177.6593\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.8470 - val_loss: 177.6403\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.8386 - val_loss: 177.6213\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.8302 - val_loss: 177.6023\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.8219 - val_loss: 177.5833\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.8135 - val_loss: 177.5643\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 73.8051 - val_loss: 177.5453\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.7967 - val_loss: 177.5263\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.7883 - val_loss: 177.5072\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.7800 - val_loss: 177.4883\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 73.7716 - val_loss: 177.4693\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.7632 - val_loss: 177.4503\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.7549 - val_loss: 177.4313\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.7465 - val_loss: 177.4123\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.7381 - val_loss: 177.3933\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.7297 - val_loss: 177.3743\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.7214 - val_loss: 177.3553\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.7130 - val_loss: 177.3363\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.7046 - val_loss: 177.3173\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.6962 - val_loss: 177.2983\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.6879 - val_loss: 177.2793\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.6795 - val_loss: 177.2603\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.6711 - val_loss: 177.2413\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.6627 - val_loss: 177.2223\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.6544 - val_loss: 177.2032\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.6460 - val_loss: 177.1843\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.6376 - val_loss: 177.1653\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 73.6292 - val_loss: 177.1463\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 73.6208 - val_loss: 177.1273\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.6125 - val_loss: 177.1083\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.6041 - val_loss: 177.0893\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.5957 - val_loss: 177.0703\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.5874 - val_loss: 177.0513\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 73.5790 - val_loss: 177.0323\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.5706 - val_loss: 177.0133\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.5622 - val_loss: 176.9943\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.5538 - val_loss: 176.9753\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 73.5455 - val_loss: 176.9563\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.5371 - val_loss: 176.9373\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.5287 - val_loss: 176.9183\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.5204 - val_loss: 176.8993\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.5120 - val_loss: 176.8803\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.5036 - val_loss: 176.8613\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.4952 - val_loss: 176.8423\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.4869 - val_loss: 176.8233\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.4785 - val_loss: 176.8043\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.4701 - val_loss: 176.7853\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.4617 - val_loss: 176.7663\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.4534 - val_loss: 176.7473\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 73.4450 - val_loss: 176.7283\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.4366 - val_loss: 176.7093\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.4282 - val_loss: 176.6903\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 73.4199 - val_loss: 176.6713\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.4115 - val_loss: 176.6523\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.4031 - val_loss: 176.6333\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.3947 - val_loss: 176.6143\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.3864 - val_loss: 176.5953\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.3780 - val_loss: 176.5763\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.3696 - val_loss: 176.5573\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.3612 - val_loss: 176.5383\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.3529 - val_loss: 176.5193\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.3445 - val_loss: 176.5003\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.3361 - val_loss: 176.4813\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.3277 - val_loss: 176.4623\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 73.3194 - val_loss: 176.4433\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.3110 - val_loss: 176.4243\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.3026 - val_loss: 176.4053\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 73.2942 - val_loss: 176.3863\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 73.2859 - val_loss: 176.3673\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.2775 - val_loss: 176.3483\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.2691 - val_loss: 176.3293\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.2607 - val_loss: 176.3103\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.2524 - val_loss: 176.2913\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.2440 - val_loss: 176.2723\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 73.2356 - val_loss: 176.2533\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.2272 - val_loss: 176.2343\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 73.2189 - val_loss: 176.2153\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.2105 - val_loss: 176.1963\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.2021 - val_loss: 176.1773\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.1937 - val_loss: 176.1583\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.1854 - val_loss: 176.1393\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.1770 - val_loss: 176.1203\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 73.1686 - val_loss: 176.1013\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.1602 - val_loss: 176.0823\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.1519 - val_loss: 176.0633\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.1435 - val_loss: 176.0443\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.1351 - val_loss: 176.0253\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 73.1267 - val_loss: 176.0063\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.1184 - val_loss: 175.9873\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 73.1100 - val_loss: 175.9683\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 73.1016 - val_loss: 175.9493\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.0932 - val_loss: 175.9303\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.0849 - val_loss: 175.9113\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 73.0765 - val_loss: 175.8923\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.0681 - val_loss: 175.8733\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 73.0597 - val_loss: 175.8543\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.0514 - val_loss: 175.8353\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.0430 - val_loss: 175.8163\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 73.0346 - val_loss: 175.7973\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.0262 - val_loss: 175.7783\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.0179 - val_loss: 175.7593\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 73.0095 - val_loss: 175.7403\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 73.0011 - val_loss: 175.7213\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 72.9927 - val_loss: 175.7023\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 72.9844 - val_loss: 175.6833\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 72.9760 - val_loss: 175.6643\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 72.9676 - val_loss: 175.6453\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 72.9592 - val_loss: 175.6263\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 72.9509 - val_loss: 175.6073\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 72.9425 - val_loss: 175.5883\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 72.9341 - val_loss: 175.5693\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 72.9257 - val_loss: 175.5503\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 72.9174 - val_loss: 175.5313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cc0316650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aldrnoBbApPx"
      },
      "source": [
        "`val_loss` denotes how far could your models prediction be from the actual label.\n",
        "\n",
        "So let's say if you give the input `x = 10` to your model you are expecting the ideal output to be 100, why? Because `y = 10*x = 10*10 = 100`.\n",
        "\n",
        "Now you would get 100 if you're not using Machine Learning.\n",
        "If you use the Approach 1 (that works on Crisp / Boolean Logic) you would get an exact 100, but if you use machine learning (that uses fuzzy logic) you would get the value close to 100 but never exactly 100. \n",
        "\n",
        "In the current scenario it would be `10*x  val_loss = 10*10  107.8904`\n",
        "\n",
        "Because the validation loss is 107.8904, and our intention is to reduce the loss and bring it down as closer to zero as much as we can."
      ]
    }
  ]
}